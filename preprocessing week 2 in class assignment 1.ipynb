{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6964f712",
   "metadata": {},
   "source": [
    "# Titanic Dataset Preprocessing (Modified Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9316ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "# ---------------------------------\n",
    "# Load Dataset\n",
    "# ---------------------------------\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# ---------------------------------\n",
    "# Step 1: Handling Missing Values (Revised)\n",
    "# ---------------------------------\n",
    "print(\"\\nMissing values before processing:\\n\", df.isnull().sum())\n",
    "\n",
    "df1 = df.copy()\n",
    "\n",
    "# Fill Age using median age within each Sex group\n",
    "df1[\"Age\"] = df1.groupby(\"Sex\")[\"Age\"].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Fill Embarked using most frequent value\n",
    "df1[\"Embarked\"] = df1[\"Embarked\"].fillna(df1[\"Embarked\"].mode()[0])\n",
    "\n",
    "# Drop Cabin due to excessive missing data\n",
    "df1.drop(columns=[\"Cabin\"], inplace=True)\n",
    "\n",
    "print(\"\\nMissing values after processing:\\n\", df1.isnull().sum())\n",
    "\n",
    "# ---------------------------------\n",
    "# Step 2: Noise Simulation and Smoothing\n",
    "# ---------------------------------\n",
    "np.random.seed(1)\n",
    "df1[\"Fare_noisy\"] = df1[\"Fare\"] + np.random.normal(0, 3, len(df1))\n",
    "\n",
    "# Exponential smoothing instead of moving average\n",
    "df1[\"Fare_smooth\"] = df1[\"Fare_noisy\"].ewm(span=10).mean()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df1[\"Fare_noisy\"], alpha=0.4, label=\"Noisy Fare\")\n",
    "plt.plot(df1[\"Fare_smooth\"], color=\"red\", label=\"Smoothed Fare\")\n",
    "plt.legend()\n",
    "plt.title(\"Noise Reduction using Exponential Smoothing\")\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------------\n",
    "# Step 3: Outlier Detection Using Modified Z-Score\n",
    "# ---------------------------------\n",
    "median_fare = np.median(df1[\"Fare\"])\n",
    "mad = np.median(np.abs(df1[\"Fare\"] - median_fare))\n",
    "modified_z = 0.6745 * (df1[\"Fare\"] - median_fare) / mad\n",
    "\n",
    "df_no_outliers = df1[np.abs(modified_z) < 3.5]\n",
    "\n",
    "print(\"\\nOriginal shape:\", df1.shape)\n",
    "print(\"After removing outliers:\", df_no_outliers.shape)\n",
    "\n",
    "# ---------------------------------\n",
    "# Step 4: Feature Transformation\n",
    "# ---------------------------------\n",
    "df2 = df_no_outliers.copy()\n",
    "\n",
    "# Create family size feature\n",
    "df2[\"FamilySize\"] = df2[\"SibSp\"] + df2[\"Parch\"] + 1\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df2 = pd.get_dummies(df2, columns=[\"Sex\", \"Embarked\"], drop_first=True)\n",
    "\n",
    "print(\"\\nTransformed dataset preview:\")\n",
    "display(df2.head())\n",
    "\n",
    "# ---------------------------------\n",
    "# Step 5: Feature Scaling\n",
    "# ---------------------------------\n",
    "num_cols = [\"Age\", \"Fare\", \"FamilySize\"]\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "df2[num_cols] = std_scaler.fit_transform(df2[num_cols])\n",
    "\n",
    "mm_scaler = MinMaxScaler()\n",
    "df2[num_cols] = mm_scaler.fit_transform(df2[num_cols])\n",
    "\n",
    "print(\"\\nScaled feature sample:\")\n",
    "display(df2[num_cols].head())\n",
    "\n",
    "# ---------------------------------\n",
    "# Step 6: Distribution Visualization\n",
    "# ---------------------------------\n",
    "plt.figure()\n",
    "plt.hist(df[\"Fare\"], bins=30, alpha=0.5, label=\"Original Fare\")\n",
    "plt.hist(df_no_outliers[\"Fare\"], bins=30, alpha=0.5, label=\"After Outlier Removal\")\n",
    "plt.legend()\n",
    "plt.title(\"Fare Distribution Before and After Cleaning\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nData preprocessing complete.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
